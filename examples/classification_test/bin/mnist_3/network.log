network init start

hyperparameters
init_weight_range 0.000000 ,xavier
learning_rate 0.001000
lambda1 0.000010
lambda2 0.000010
dropout 0.200000
minibatch size 32

   DENSE CONVOLUTION  [   28    28     1] [    3     3     8] [   28    28     9] [        72          8][     62720]
                RELU  [   28    28     9] [    1     1     1] [   28    28     9] [         0          0][     14112]
   DENSE CONVOLUTION  [   28    28     9] [    3     3     8] [   28    28    17] [       648          8][    514304]
                RELU  [   28    28    17] [    1     1     1] [   28    28    17] [         0          0][     26656]
   DENSE CONVOLUTION  [   28    28    17] [    3     3     8] [   28    28    25] [      1224          8][    965888]
                RELU  [   28    28    25] [    1     1     1] [   28    28    25] [         0          0][     39200]
   DENSE CONVOLUTION  [   28    28    25] [    3     3     8] [   28    28    33] [      1800          8][   1417472]
                RELU  [   28    28    33] [    1     1     1] [   28    28    33] [         0          0][     51744]
         CONVOLUTION  [   28    28    33] [    1     1    32] [   28    28    32] [      1056         32][    852992]
                RELU  [   28    28    32] [    1     1     1] [   28    28    32] [         0          0][     50176]
         MAX POOLING  [   28    28    32] [    2     2     1] [   14    14    32] [         0          0][     50176]
   DENSE CONVOLUTION  [   14    14    32] [    3     3     8] [   14    14    40] [      2304          8][    453152]
                RELU  [   14    14    40] [    1     1     1] [   14    14    40] [         0          0][     15680]
   DENSE CONVOLUTION  [   14    14    40] [    3     3     8] [   14    14    48] [      2880          8][    566048]
                RELU  [   14    14    48] [    1     1     1] [   14    14    48] [         0          0][     18816]
   DENSE CONVOLUTION  [   14    14    48] [    3     3     8] [   14    14    56] [      3456          8][    678944]
                RELU  [   14    14    56] [    1     1     1] [   14    14    56] [         0          0][     21952]
   DENSE CONVOLUTION  [   14    14    56] [    3     3     8] [   14    14    64] [      4032          8][    791840]
                RELU  [   14    14    64] [    1     1     1] [   14    14    64] [         0          0][     25088]
         CONVOLUTION  [   14    14    64] [    1     1    32] [   14    14    32] [      2048         32][    407680]
                RELU  [   14    14    32] [    1     1     1] [   14    14    32] [         0          0][     12544]
         MAX POOLING  [   14    14    32] [    2     2     1] [    7     7    32] [         0          0][     12544]
             DROPOUT  [    7     7    32] [    1     1     1] [    7     7    32] [         0          0][      3136]
                  FC  [    7     7    32] [    1     1    10] [    1     1    10] [     15680         10][     31380]

input_geometry  [28 28 1]
output_geometry [1 1 10]
network flops operations 7084244 FLOPS, 0.007084 GFLOPS
init DONE

network destructor done
